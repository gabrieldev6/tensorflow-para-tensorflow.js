# -*- coding: utf-8 -*-
"""Cópia de convertendo modelo pytorch para tensorflowjs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1av9NyFd3od5IfvMv-iQXnHjz6KUCShRy
"""



# Commented out IPython magic to ensure Python compatibility.
# Download YOLOv7 repository and install requirements
!git clone https://github.com/WongKinYiu/yolov7
# %cd yolov7
!pip install -r requirements.txt

# Commented out IPython magic to ensure Python compatibility.
# baixa o projeto que esta no roboflow
# %cd /content/yolov7
!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="AUnJBr8q5M0CcpEMcylG")
project = rf.workspace("atividade-ofwyn").project("drone-teste")
dataset = project.version(2).download("yolov7")

# baixa o peso original do wongKin com coco 2017
!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt



"""Configuring the model architecture.


E antes de iniciar o treinamento, temos que configurar um arquivo .yaml com os parâmetros que queremos utilizar.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile cfg/training/yolov7_drone-tiny.yaml
# # parameters
# nc: 1  # number of classes
# depth_multiple: 1.0  # model depth multiple
# width_multiple: 1.0  # layer channel multiple
# 
# # anchors
# anchors:
#   - [10,13, 16,30, 33,23]  # P3/8
#   - [30,61, 62,45, 59,119]  # P4/16
#   - [116,90, 156,198, 373,326]  # P5/32
# 
# # yolov7-tiny backbone
# backbone:
#   # [from, number, module, args] c2, k=1, s=1, p=None, g=1, act=True
#   [[-1, 1, Conv, [32, 3, 2, None, 1, nn.LeakyReLU(0.1)]],  # 0-P1/2
# 
#   [-1, 1, Conv, [64, 3, 2, None, 1, nn.LeakyReLU(0.1)]],  # 1-P2/4
# 
#   [-1, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 7
# 
#   [-1, 1, MP, []],  # 8-P3/8
#   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 14
# 
#   [-1, 1, MP, []],  # 15-P4/16
#   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 21
# 
#   [-1, 1, MP, []],  # 22-P5/32
#   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [512, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 28
#   ]
# 
# # yolov7-tiny head
# head:
#   [[-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, SP, [5]],
#   [-2, 1, SP, [9]],
#   [-3, 1, SP, [13]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -7], 1, Concat, [1]],
#   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 37
# 
#   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
#   [21, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]], # route backbone P4
#   [[-1, -2], 1, Concat, [1]],
# 
#   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 47
# 
#   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
#   [14, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]], # route backbone P3
#   [[-1, -2], 1, Concat, [1]],
# 
#   [-1, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 57
# 
#   [-1, 1, Conv, [128, 3, 2, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, 47], 1, Concat, [1]],
# 
#   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 65
# 
#   [-1, 1, Conv, [256, 3, 2, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, 37], 1, Concat, [1]],
# 
#   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-2, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [[-1, -2, -3, -4], 1, Concat, [1]],
#   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 73
# 
#   [57, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [65, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
#   [73, 1, Conv, [512, 3, 1, None, 1, nn.LeakyReLU(0.1)]],
# 
#   [[74,75,76], 1, IDetect, [nc, anchors]],   # Detect(P3, P4, P5)
#   ]

"""treinamento do modelo"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov7
!python train.py --epochs 10 --workers 4 --device 0 --batch-size 32 \
--data {dataset.location}/data.yaml --img 640 640 --cfg cfg/training/yolov7_drone-tiny.yaml \
--weights 'best5.pt' --name yolov7_tiny_drone --hyp data/hyp.scratch.tiny.yaml

"""Exporta para onnx"""

# bibliotecas necessarias para exporta para tensorflow
!pip install -U onnx
!pip install -U onnx-tf

!python export.py --weights runs/train/yolov7_tiny_drone/weights/best.pt  \
        --grid  \
        --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 \
        --img-size 640 640 --max-wh 640 # For onnxruntime, you need to specify this value as an integer, when it is 0 it means agnostic NMS,
                     # otherwise it is non-agnostic NMS

# testa o modelo
!python detect.py --weights runs/train/weights/best.pt --conf 0.1 --source drone/teste2.mp4

import torch.onnx
import onnx
from onnx_tf.backend import prepare
onnx_model_path = 'runs/train/yolov7_tiny_drone/weights/best.onnx'


onnx_model = onnx.load(onnx_model_path)
tf_rep = prepare(onnx_model)

tf_model_dir = 'runs/tf'
tf_rep.export_graph(tf_model_dir)
tfjs_model_dir = f"{tf_model_dir}/tfjs"

tfjs_convert_command = f"""tensorflowjs_converter
                 --input_format=tf_saved_model
                 --output_format=tfjs_graph_model
                 --signature_name=serving_default
                 --saved_model_tags=serve
                 "{tf_model_dir}"
                 "{tfjs_model_dir}"
                 """
tfjs_convert_command = " ".join(tfjs_convert_command.split())

!pip install -U tensorflowjs

# Commented out IPython magic to ensure Python compatibility.
# %sx $tfjs_convert_command

# baixar os pesos em tensorflow js
!tar vcfz {tfjs_model_dir}.tar.gz {tfjs_model_dir}

# Commented out IPython magic to ensure Python compatibility.
# baixar arquivos de teste
# %cd /content/yolov7
!zip -r teste.zip runs/detect/exp2